{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Stima dei Costi per il Fine-Tuning di davinci-002"
      ],
      "metadata": {
        "id": "ipuFH81FSbOj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In questo notebook vado  inizialmente a fare una stima di quanto costerà effettuare il fine-tuning di davinci-002 e lo confronto con i costi nel caso effettuassi il fine-tuning di gpt-3.5-turbo"
      ],
      "metadata": {
        "id": "SzY3cGc1SiAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken\n",
        "!pip install python-dotenv"
      ],
      "metadata": {
        "id": "TzdMW3NVzpDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive, files\n",
        "import os\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "drive.mount(\"/content/drive/\", force_remount=False)\n",
        "%cd \"/content/drive/My Drive/\"\n",
        "load_dotenv('./Lab_Python/.env')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_j6GoTq-zvLR",
        "outputId": "c68c2585-78ef-4aed-e47a-6804bc64033f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "/content/drive/My Drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carico il dataset con il prompt e la completion, in questo caso la completion non è generata da text-davinci-003"
      ],
      "metadata": {
        "id": "VeewrIttg8lV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8UCWeuX-zjXl"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open('./Tesi/prova_domande_fine_tuning.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "json_str = json.dumps(data)\n",
        "\n",
        "f.close()\n",
        "\n",
        "json_str"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Costo fine-tuning di gpt-3.5-turbo con i miei documenti"
      ],
      "metadata": {
        "id": "t3RzH1ZSW9hJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "n_epoche = 6\n",
        "\n",
        "def stampa_costo_training(texts):\n",
        "  import tiktoken\n",
        "  enc = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
        "  total_tokens=(len(enc.encode(texts)))\n",
        "  print(f'Totale token:{total_tokens}')\n",
        "  costo_training = (total_tokens/1000* 0.0080) * n_epoche\n",
        "  print(f'Costo training GPT-3.5-Turbo in $ (OpenAI): {costo_training:.6f}')\n",
        "  return costo_training\n",
        "\n",
        "costo_training_GPT = stampa_costo_training(json_str)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGq5hMop2fpC",
        "outputId": "7186edac-2a05-47bb-9709-5220adcd94f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Totale token:112750\n",
            "Costo training GPT-3.5-Turbo in $ (OpenAI): 5.412000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Costo utilizzo del modello fine-tunato con gpt-3.5-turbo"
      ],
      "metadata": {
        "id": "pA-Yehg1XEuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def costo_utilizzo_gpt(texts):\n",
        "    import tiktoken\n",
        "    enc = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
        "    total_tokens=(len(enc.encode(texts)))\n",
        "    print(f'Totale token:{total_tokens}')\n",
        "    costo_input = (total_tokens/1000* 0.0030)\n",
        "    costo_output = (total_tokens/1000* 0.0060)\n",
        "    costo_totale = costo_input + costo_output\n",
        "    print(f'Costo utilizzo GPT-3.5-turbo in $ (OpenAI): {costo_totale:.6f}')\n",
        "    return costo_totale\n",
        "\n",
        "costo_utilizzo_gpt = costo_utilizzo_gpt(json_str)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNF5FVSp6AUW",
        "outputId": "b23bd6c1-dcbc-4e85-9151-ce8f355542e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Totale token:112750\n",
            "Costo utilizzo GPT-3.5-turbo in $ (OpenAI): 1.014750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Costo stimato fine-tuning con Davinci-002"
      ],
      "metadata": {
        "id": "KoYGFQTzyg_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "n_epoche = 6\n",
        "def stampa_costo_embeddings(texts):\n",
        "  import tiktoken\n",
        "  enc = tiktoken.encoding_for_model(\"davinci-002\")\n",
        "  total_tokens=(len(enc.encode(texts)))\n",
        "  print(f'Totale token:{total_tokens}')\n",
        "  costo_training = (total_tokens/1000* 0.0060) * n_epoche\n",
        "  print(f'Costo training Davinci-002 in $ (OpenAI): {costo_training:.6f}')\n",
        "  return costo_training\n",
        "\n",
        "costo_training_davinci = stampa_costo_embeddings(json_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdYYeayB4yuU",
        "outputId": "33045317-0755-4e09-d350-42e9ba2aec51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Totale token:112750\n",
            "Costo training Davinci-002 in $ (OpenAI): 4.059000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Costo utilizzo del modello fine-tunato con davinci-002"
      ],
      "metadata": {
        "id": "PqKJdtA-ymZ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def costo_utilizzo(texts):\n",
        "    import tiktoken\n",
        "    enc = tiktoken.encoding_for_model(\"davinci-002\")\n",
        "    total_tokens=(len(enc.encode(texts)))\n",
        "    print(f'Totale token:{total_tokens}')\n",
        "    costo_input = (total_tokens/1000* 0.0120)\n",
        "    costo_output = (total_tokens/1000* 0.0120)\n",
        "    costo_totale = costo_input + costo_output\n",
        "    print(f'Costo utilizzo Davinci-002 in $ (OpenAI): {costo_totale:.6f}')\n",
        "    return costo_totale\n",
        "costo_utilizzo_davinci = costo_utilizzo(json_str)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0z38EOJu5tXR",
        "outputId": "b9697b31-55f3-485b-c1fc-f92728591c16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Totale token:112750\n",
            "Costo utilizzo Davinci-002 in $ (OpenAI): 2.706000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Costi complessivi:"
      ],
      "metadata": {
        "id": "O9x7dhgz7D0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "costo_complessivo_gpt = costo_training_GPT +  costo_utilizzo_gpt\n",
        "costo_complessivo_davinci = costo_training_davinci + costo_utilizzo_davinci\n",
        "\n",
        "print(f'Costo complessivo GPT-3.5-turbo in $ (OpenAI): {costo_complessivo_gpt:.6f}')\n",
        "print(f'Costo complessivo davinci-002 in $ (OpenAI): {costo_complessivo_davinci:.6f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeCOiCLG6LoA",
        "outputId": "61fd00de-e554-44d8-9b27-a0619abd8d40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Costo complessivo GPT-3.5-turbo in $ (OpenAI): 6.426750\n",
            "Costo complessivo davinci-002 in $ (OpenAI): 5.412000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Per 90.000 token, il costo cambia come segue:\n",
        "\n",
        "GPT-3.5-turbo:\n",
        "\n",
        "Costo di addestramento: €0.0080 per 1K tokens x 90 = €0.72\n",
        "Costo di utilizzo in input: €0.0030 per 1K tokens x 90 = €0.27\n",
        "Costo di utilizzo in output: €0.0060 per 1K tokens x 90 = €0.54\n",
        "davinci-002:\n",
        "\n",
        "Costo di addestramento: €0.0060 per 1K tokens x 90 = €0.54\n",
        "Costo di utilizzo in input: €0.0120 per 1K tokens x 90 = €1.08\n",
        "Costo di utilizzo in output: €0.0120 per 1K tokens x 90 = €1.08\n",
        "Quindi, per 90.000 token, il fine-tuning di davinci-002 risulta essere più costoso rispetto a quello di GPT-3.5-turbo."
      ],
      "metadata": {
        "id": "8GI-h9hO5Jf3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FINE-TUNING"
      ],
      "metadata": {
        "id": "-CuJtHyEy1Y7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai==0.28"
      ],
      "metadata": {
        "id": "j6StB7Wrm49K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converto il file json in un file json lista in quanto è il tipo di file accettato da OpenAI"
      ],
      "metadata": {
        "id": "3BeGRdfMy7Wg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def convert_json_to_jsonl(json_filename, jsonl_filename):\n",
        "    with open(json_filename, 'r') as json_file:\n",
        "        data = json.load(json_file)\n",
        "\n",
        "    with open(jsonl_filename, 'w') as jsonl_file:\n",
        "        for item in data:\n",
        "            jsonl_file.write(json.dumps(item) + '\\n')\n",
        "\n",
        "# Example usage:\n",
        "convert_json_to_jsonl('./Tesi/prova_domande_fine_tuning.json', './Tesi/solo_domande_ft_list.json')\n"
      ],
      "metadata": {
        "id": "0GhKhEjxHN1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carico il file su OpenAI che crea un id del file che ci servirà per il fine-tuning"
      ],
      "metadata": {
        "id": "5KgDJ9OLzMtt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "c = openai.File.create(\n",
        "  file=open(\"./Tesi/solo_domande_ft_list.json\", \"rb\"),\n",
        "  purpose='fine-tune'\n",
        ")\n",
        "\n",
        "print(c)\n",
        "\n"
      ],
      "metadata": {
        "id": "_y_kfE4n5IST",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bcef4e9-e9bc-4bfd-bad7-f3f996d02b36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"object\": \"file\",\n",
            "  \"id\": \"file-B5U4uBFyL8HbLT9dR9EySsOh\",\n",
            "  \"purpose\": \"fine-tune\",\n",
            "  \"filename\": \"file\",\n",
            "  \"bytes\": 346097,\n",
            "  \"created_at\": 1701083606,\n",
            "  \"status\": \"uploaded\",\n",
            "  \"status_details\": null\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Avvio l'effettivo fine-tuning passando id file, modello e un suffisso a scelta, inoltre possiamo scegliere l'iperparametri, parto con un numero di epoche uguale a 5, se non passiamo nulla lo sceglierà in automatico."
      ],
      "metadata": {
        "id": "ufku4FlIzYRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = openai.FineTuningJob.create(training_file=\"file-B5U4uBFyL8HbLT9dR9EySsOh\", model=\"davinci-002\", suffix=\"test-Signorile\",hyperparameters={\"n_epochs\":6})\n",
        "\n",
        "print(r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szUBZdL3H-eO",
        "outputId": "76bb4824-d740-4b2f-b039-ac08e8f886f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"object\": \"fine_tuning.job\",\n",
            "  \"id\": \"ftjob-A5MeFOFqF5YbdDDPCaXxjRmW\",\n",
            "  \"model\": \"davinci-002\",\n",
            "  \"created_at\": 1701083659,\n",
            "  \"finished_at\": null,\n",
            "  \"fine_tuned_model\": null,\n",
            "  \"organization_id\": \"org-OF04YbDrGXeJxlDm77negXuJ\",\n",
            "  \"result_files\": [],\n",
            "  \"status\": \"validating_files\",\n",
            "  \"validation_file\": null,\n",
            "  \"training_file\": \"file-B5U4uBFyL8HbLT9dR9EySsOh\",\n",
            "  \"hyperparameters\": {\n",
            "    \"n_epochs\": 6,\n",
            "    \"batch_size\": \"auto\",\n",
            "    \"learning_rate_multiplier\": \"auto\"\n",
            "  },\n",
            "  \"trained_tokens\": null,\n",
            "  \"error\": null\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uso il jobname per controllare lo status del fine-tuning"
      ],
      "metadata": {
        "id": "_V-Fc3QLzqft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "jobname = \"ftjob-A5MeFOFqF5YbdDDPCaXxjRmW\"\n",
        "\n",
        "r = openai.FineTuningJob.retrieve(jobname)\n",
        "e = openai.FineTuningJob.list_events(id=jobname, limit=10)\n",
        "print(f\"status: {r}\")\n",
        "print(\"\\n\\n\\n\")\n",
        "print(f\"events: {e}\")"
      ],
      "metadata": {
        "id": "aeNSgX5YHNHh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77255d4b-3743-449b-8893-fb17a4da1f60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "status: {\n",
            "  \"object\": \"fine_tuning.job\",\n",
            "  \"id\": \"ftjob-A5MeFOFqF5YbdDDPCaXxjRmW\",\n",
            "  \"model\": \"davinci-002\",\n",
            "  \"created_at\": 1701083659,\n",
            "  \"finished_at\": 1701083988,\n",
            "  \"fine_tuned_model\": \"ft:davinci-002:links:test-signorile:8PTwTi0r\",\n",
            "  \"organization_id\": \"org-OF04YbDrGXeJxlDm77negXuJ\",\n",
            "  \"result_files\": [\n",
            "    \"file-Kk8jh4NetdILLrj6i7Qqb26e\"\n",
            "  ],\n",
            "  \"status\": \"succeeded\",\n",
            "  \"validation_file\": null,\n",
            "  \"training_file\": \"file-B5U4uBFyL8HbLT9dR9EySsOh\",\n",
            "  \"hyperparameters\": {\n",
            "    \"n_epochs\": 6,\n",
            "    \"batch_size\": 1,\n",
            "    \"learning_rate_multiplier\": 2\n",
            "  },\n",
            "  \"trained_tokens\": 613428,\n",
            "  \"error\": null\n",
            "}\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "events: {\n",
            "  \"object\": \"list\",\n",
            "  \"data\": [\n",
            "    {\n",
            "      \"object\": \"fine_tuning.job.event\",\n",
            "      \"id\": \"ftevent-KE7HwkK6CXca5HHYIOAVCS6H\",\n",
            "      \"created_at\": 1701083993,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"The job has successfully completed\",\n",
            "      \"data\": {},\n",
            "      \"type\": \"message\"\n",
            "    },\n",
            "    {\n",
            "      \"object\": \"fine_tuning.job.event\",\n",
            "      \"id\": \"ftevent-OixNyijf6mbMQkvrL5u0R7Sw\",\n",
            "      \"created_at\": 1701083989,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"New fine-tuned model created: ft:davinci-002:links:test-signorile:8PTwTi0r\",\n",
            "      \"data\": {},\n",
            "      \"type\": \"message\"\n",
            "    },\n",
            "    {\n",
            "      \"object\": \"fine_tuning.job.event\",\n",
            "      \"id\": \"ftevent-QWX7J0shNC5YgyaQZvqZv5OJ\",\n",
            "      \"created_at\": 1701083980,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Step 581/588: training loss=0.76\",\n",
            "      \"data\": {\n",
            "        \"step\": 581,\n",
            "        \"train_loss\": 0.7629403471946716,\n",
            "        \"train_mean_token_accuracy\": 0.7990338206291199\n",
            "      },\n",
            "      \"type\": \"metrics\"\n",
            "    },\n",
            "    {\n",
            "      \"object\": \"fine_tuning.job.event\",\n",
            "      \"id\": \"ftevent-lyS1uqHCG3TTOqyCqB1NnjOA\",\n",
            "      \"created_at\": 1701083975,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Step 571/588: training loss=0.71\",\n",
            "      \"data\": {\n",
            "        \"step\": 571,\n",
            "        \"train_loss\": 0.7081358432769775,\n",
            "        \"train_mean_token_accuracy\": 0.8135592937469482\n",
            "      },\n",
            "      \"type\": \"metrics\"\n",
            "    },\n",
            "    {\n",
            "      \"object\": \"fine_tuning.job.event\",\n",
            "      \"id\": \"ftevent-QWsy8GEK1obCcPfhWdN1txN5\",\n",
            "      \"created_at\": 1701083972,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Step 561/588: training loss=0.57\",\n",
            "      \"data\": {\n",
            "        \"step\": 561,\n",
            "        \"train_loss\": 0.5735676884651184,\n",
            "        \"train_mean_token_accuracy\": 0.8560548424720764\n",
            "      },\n",
            "      \"type\": \"metrics\"\n",
            "    },\n",
            "    {\n",
            "      \"object\": \"fine_tuning.job.event\",\n",
            "      \"id\": \"ftevent-jmemcQ5n2ll0UWfqM8KAZGpo\",\n",
            "      \"created_at\": 1701083967,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Step 551/588: training loss=0.51\",\n",
            "      \"data\": {\n",
            "        \"step\": 551,\n",
            "        \"train_loss\": 0.5055776238441467,\n",
            "        \"train_mean_token_accuracy\": 0.883502721786499\n",
            "      },\n",
            "      \"type\": \"metrics\"\n",
            "    },\n",
            "    {\n",
            "      \"object\": \"fine_tuning.job.event\",\n",
            "      \"id\": \"ftevent-QY1SIUUHArsAX2h3KVOxdORG\",\n",
            "      \"created_at\": 1701083965,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Step 541/588: training loss=0.28\",\n",
            "      \"data\": {\n",
            "        \"step\": 541,\n",
            "        \"train_loss\": 0.2756809890270233,\n",
            "        \"train_mean_token_accuracy\": 0.939393937587738\n",
            "      },\n",
            "      \"type\": \"metrics\"\n",
            "    },\n",
            "    {\n",
            "      \"object\": \"fine_tuning.job.event\",\n",
            "      \"id\": \"ftevent-4CBRCBNTojRvkfIub4aPBMjg\",\n",
            "      \"created_at\": 1701083960,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Step 531/588: training loss=1.16\",\n",
            "      \"data\": {\n",
            "        \"step\": 531,\n",
            "        \"train_loss\": 1.1589775085449219,\n",
            "        \"train_mean_token_accuracy\": 0.7179023623466492\n",
            "      },\n",
            "      \"type\": \"metrics\"\n",
            "    },\n",
            "    {\n",
            "      \"object\": \"fine_tuning.job.event\",\n",
            "      \"id\": \"ftevent-mLtqKoJaZ35eujoxEfmBsh8b\",\n",
            "      \"created_at\": 1701083958,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Step 521/588: training loss=0.96\",\n",
            "      \"data\": {\n",
            "        \"step\": 521,\n",
            "        \"train_loss\": 0.9590765237808228,\n",
            "        \"train_mean_token_accuracy\": 0.7834960222244263\n",
            "      },\n",
            "      \"type\": \"metrics\"\n",
            "    },\n",
            "    {\n",
            "      \"object\": \"fine_tuning.job.event\",\n",
            "      \"id\": \"ftevent-PtAOQmXDbsYfWx70Cf0rL91I\",\n",
            "      \"created_at\": 1701083953,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Step 511/588: training loss=0.83\",\n",
            "      \"data\": {\n",
            "        \"step\": 511,\n",
            "        \"train_loss\": 0.8263291716575623,\n",
            "        \"train_mean_token_accuracy\": 0.7932148575782776\n",
            "      },\n",
            "      \"type\": \"metrics\"\n",
            "    }\n",
            "  ],\n",
            "  \"has_more\": true\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Costo reale fine-tuning: 3.6$"
      ],
      "metadata": {
        "id": "OKYkT7HyOicY"
      }
    }
  ]
}