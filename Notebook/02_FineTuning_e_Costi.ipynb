{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "5#Stima dei Costi per il Fine-Tuning di davinci-002"
      ],
      "metadata": {
        "id": "ipuFH81FSbOj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In questo notebook vado  inizialmente a fare una stima di quanto costerà effettuare il fine-tuning di davinci-002 e lo confronto con i costi nel caso effettuassi il fine-tuning di gpt-3.5-turbo"
      ],
      "metadata": {
        "id": "SzY3cGc1SiAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "id": "TzdMW3NVzpDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive, files\n",
        "import os\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "drive.mount(\"/content/drive/\", force_remount=False)\n",
        "%cd \"/content/drive/My Drive/\"\n",
        "load_dotenv('./Lab_Python/.env')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_j6GoTq-zvLR",
        "outputId": "ddcc332c-5cd3-4172-fdd8-2605f815c73d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "/content/drive/My Drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8UCWeuX-zjXl"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open('./Tesi/fine_tune_improved.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "json_str = json.dumps(data)\n",
        "\n",
        "f.close()\n",
        "\n",
        "json_str"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Costo fine-tuning di gpt-3.5-turbo con i miei documenti"
      ],
      "metadata": {
        "id": "t3RzH1ZSW9hJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "n_epoche = 4\n",
        "\n",
        "def stampa_costo_training(texts):\n",
        "  import tiktoken\n",
        "  enc = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
        "  total_tokens=(len(enc.encode(texts)))\n",
        "  print(f'Totale token:{total_tokens}')\n",
        "  costo_training = (total_tokens/1000* 0.0080) * n_epoche\n",
        "  print(f'Costo training GPT-3.5-Turbo in $ (OpenAI): {costo_training:.6f}')\n",
        "  return costo_training\n",
        "\n",
        "costo_training_GPT = stampa_costo_training(json_str)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGq5hMop2fpC",
        "outputId": "ed0ad73e-8b14-4383-b49c-7abef187e0be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Totale token:69375\n",
            "Costo training GPT-3.5-Turbo in $ (OpenAI): 2.220000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Costo utilizzo del modello fine-tunato con gpt-3.5-turbo"
      ],
      "metadata": {
        "id": "pA-Yehg1XEuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def costo_utilizzo_gpt(texts):\n",
        "    import tiktoken\n",
        "    enc = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
        "    total_tokens=(len(enc.encode(texts)))\n",
        "    print(f'Totale token:{total_tokens}')\n",
        "    costo_input = (total_tokens/1000* 0.0030)\n",
        "    costo_output = (total_tokens/1000* 0.0060)\n",
        "    costo_totale = costo_input + costo_output\n",
        "    print(f'Costo utilizzo GPT-3.5-turbo in $ (OpenAI): {costo_totale:.6f}')\n",
        "    return costo_totale\n",
        "\n",
        "costo_utilizzo_gpt = costo_utilizzo_gpt(json_str)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNF5FVSp6AUW",
        "outputId": "7e05b5af-9fd7-41ea-865c-897f29fa8009"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Totale token:69375\n",
            "Costo utilizzo GPT-3.5-turbo in $ (OpenAI): 0.624375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Costo stimato fine-tuning con Davinci-002"
      ],
      "metadata": {
        "id": "KoYGFQTzyg_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "n_epoche = 4\n",
        "def stampa_costo_embeddings(texts):\n",
        "  import tiktoken\n",
        "  enc = tiktoken.encoding_for_model(\"davinci-002\")\n",
        "  total_tokens=(len(enc.encode(texts)))\n",
        "  print(f'Totale token:{total_tokens}')\n",
        "  costo_training = (total_tokens/1000* 0.0060) * n_epoche\n",
        "  print(f'Costo training Davinci-002 in $ (OpenAI): {costo_training:.6f}')\n",
        "  return costo_training\n",
        "\n",
        "costo_training_davinci = stampa_costo_embeddings(json_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdYYeayB4yuU",
        "outputId": "ddf65965-0933-4ecd-e810-c7585dfee97a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Totale token:69375\n",
            "Costo training Davinci-002 in $ (OpenAI): 1.665000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Costo utilizzo del modello fine-tunato con davinci-002"
      ],
      "metadata": {
        "id": "PqKJdtA-ymZ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def costo_utilizzo(texts):\n",
        "    import tiktoken\n",
        "    enc = tiktoken.encoding_for_model(\"davinci-002\")\n",
        "    total_tokens=(len(enc.encode(texts)))\n",
        "    print(f'Totale token:{total_tokens}')\n",
        "    costo_input = (total_tokens/1000* 0.0120)\n",
        "    costo_output = (total_tokens/1000* 0.0120)\n",
        "    costo_totale = costo_input + costo_output\n",
        "    print(f'Costo utilizzo Davinci-002 in $ (OpenAI): {costo_totale:.6f}')\n",
        "    return costo_totale\n",
        "costo_utilizzo_davinci = costo_utilizzo(json_str)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0z38EOJu5tXR",
        "outputId": "9a82e454-82b7-4605-ac89-4c479a006631"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Totale token:69375\n",
            "Costo utilizzo Davinci-002 in $ (OpenAI): 1.665000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Costi complessivi:"
      ],
      "metadata": {
        "id": "O9x7dhgz7D0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "costo_complessivo_gpt = costo_training_GPT +  costo_utilizzo_gpt\n",
        "costo_complessivo_davinci = costo_training_davinci + costo_utilizzo_davinci\n",
        "\n",
        "print(f'Costo complessivo GPT-3.5-turbo in $ (OpenAI): {costo_complessivo_gpt:.6f}')\n",
        "print(f'Costo complessivo davinci-002 in $ (OpenAI): {costo_complessivo_davinci:.6f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeCOiCLG6LoA",
        "outputId": "b471496d-3ee2-43bc-e1f4-475a39ccc92e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Costo complessivo GPT-3.5-turbo in $ (OpenAI): 2.844375\n",
            "Costo complessivo davinci-002 in $ (OpenAI): 3.330000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Per 90.000 token, il costo cambia come segue:\n",
        "\n",
        "GPT-3.5-turbo:\n",
        "\n",
        "Costo di addestramento: $0.0080 per 1K tokens x 90 = $0.72\n",
        "Costo di utilizzo in input: $0.0030 per 1K tokens x 90 = $0.27\n",
        "Costo di utilizzo in output: $0.0060 per 1K tokens x 90 = $0.54\n",
        "davinci-002:\n",
        "\n",
        "Costo di addestramento: $0.0060 per 1K tokens x 90 = $0.54\n",
        "Costo di utilizzo in input: $0.0120 per 1K tokens x 90 = $1.08\n",
        "Costo di utilizzo in output: $0.0120 per 1K tokens x 90 = $1.08\n",
        "Quindi, per 90.000 token, il fine-tuning di davinci-002 risulta essere più costoso rispetto a quello di GPT-3.5-turbo."
      ],
      "metadata": {
        "id": "8GI-h9hO5Jf3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FINE-TUNING"
      ],
      "metadata": {
        "id": "-CuJtHyEy1Y7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai==0.28"
      ],
      "metadata": {
        "id": "j6StB7Wrm49K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converto il file json in un file json lista in quanto è il tipo di file accettato da OpenAI"
      ],
      "metadata": {
        "id": "3BeGRdfMy7Wg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def convert_json_to_jsonl(json_filename, jsonl_filename):\n",
        "    with open(json_filename, 'r') as json_file:\n",
        "        data = json.load(json_file)\n",
        "\n",
        "    with open(jsonl_filename, 'w') as jsonl_file:\n",
        "        for item in data:\n",
        "            jsonl_file.write(json.dumps(item) + '\\n')\n",
        "\n",
        "# Example usage:\n",
        "convert_json_to_jsonl('./Tesi/fine_tune_improved.json', './Tesi/fine_tune_improved_list.json')\n"
      ],
      "metadata": {
        "id": "0GhKhEjxHN1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carico il file su OpenAI che crea un id del file che ci servirà per il fine-tuning"
      ],
      "metadata": {
        "id": "5KgDJ9OLzMtt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "c = openai.File.create(\n",
        "  file=open(\"./Tesi/fine_tune_improved_list.json\", \"rb\"),\n",
        "  purpose='fine-tune'\n",
        ")\n",
        "\n",
        "print(c)\n",
        "\n"
      ],
      "metadata": {
        "id": "_y_kfE4n5IST",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94a5d61d-4cf7-4214-fe1e-ed2a882005b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"object\": \"file\",\n",
            "  \"id\": \"file-3KvLZc6kKFMdNrn8Juuh2LvU\",\n",
            "  \"purpose\": \"fine-tune\",\n",
            "  \"filename\": \"file\",\n",
            "  \"bytes\": 224476,\n",
            "  \"created_at\": 1700321865,\n",
            "  \"status\": \"uploaded\",\n",
            "  \"status_details\": null\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Avvio l'effettivo fine-tuning passando id file, modello e un suffisso a scelta, inoltre possiamo scegliere l'iperparametri, parto con un numero di epoche uguale a 4, se non passiamo nulla lo sceglierà in automatico."
      ],
      "metadata": {
        "id": "ufku4FlIzYRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = openai.FineTuningJob.create(training_file=\"file-3KvLZc6kKFMdNrn8Juuh2LvU\", model=\"davinci-002\", suffix=\"test-Signorile\",hyperparameters={\"n_epochs\":4})\n",
        "\n",
        "print(r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szUBZdL3H-eO",
        "outputId": "a9c9ebae-d9d2-481a-f8cc-951e99ee228f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"object\": \"fine_tuning.job\",\n",
            "  \"id\": \"ftjob-XuAnm3MliLFIyjxoJFN0wyxC\",\n",
            "  \"model\": \"davinci-002\",\n",
            "  \"created_at\": 1700321894,\n",
            "  \"finished_at\": null,\n",
            "  \"fine_tuned_model\": null,\n",
            "  \"organization_id\": \"org-OF04YbDrGXeJxlDm77negXuJ\",\n",
            "  \"result_files\": [],\n",
            "  \"status\": \"validating_files\",\n",
            "  \"validation_file\": null,\n",
            "  \"training_file\": \"file-3KvLZc6kKFMdNrn8Juuh2LvU\",\n",
            "  \"hyperparameters\": {\n",
            "    \"n_epochs\": 4,\n",
            "    \"batch_size\": \"auto\",\n",
            "    \"learning_rate_multiplier\": \"auto\"\n",
            "  },\n",
            "  \"trained_tokens\": null,\n",
            "  \"error\": null\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uso il jobname per controllare lo status del fine-tuning"
      ],
      "metadata": {
        "id": "_V-Fc3QLzqft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "jobname = \"ftjob-XuAnm3MliLFIyjxoJFN0wyxC\"\n",
        "\n",
        "r = openai.FineTuningJob.retrieve(jobname)\n",
        "e = openai.FineTuningJob.list_events(id=jobname, limit=10)\n",
        "print(f\"status: {r}\")\n",
        "print(\"\\n\\n\\n\")\n",
        "print(f\"events: {e}\")"
      ],
      "metadata": {
        "id": "aeNSgX5YHNHh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "609fb23a-a304-41f5-c258-7e8943e0ea70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "status: {\n",
            "  \"object\": \"fine_tuning.job\",\n",
            "  \"id\": \"ftjob-XuAnm3MliLFIyjxoJFN0wyxC\",\n",
            "  \"model\": \"davinci-002\",\n",
            "  \"created_at\": 1700321894,\n",
            "  \"finished_at\": null,\n",
            "  \"fine_tuned_model\": null,\n",
            "  \"organization_id\": \"org-OF04YbDrGXeJxlDm77negXuJ\",\n",
            "  \"result_files\": [],\n",
            "  \"status\": \"running\",\n",
            "  \"validation_file\": null,\n",
            "  \"training_file\": \"file-3KvLZc6kKFMdNrn8Juuh2LvU\",\n",
            "  \"hyperparameters\": {\n",
            "    \"n_epochs\": 4,\n",
            "    \"batch_size\": 1,\n",
            "    \"learning_rate_multiplier\": 2\n",
            "  },\n",
            "  \"trained_tokens\": null,\n",
            "  \"error\": null\n",
            "}\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "events: {\n",
            "  \"object\": \"list\",\n",
            "  \"data\": [\n",
            "    {\n",
            "      \"object\": \"fine_tuning.job.event\",\n",
            "      \"id\": \"ftevent-e654mLYIFSFzPFql1lhOFjfE\",\n",
            "      \"created_at\": 1700321931,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tuning job started\",\n",
            "      \"data\": null,\n",
            "      \"type\": \"message\"\n",
            "    },\n",
            "    {\n",
            "      \"object\": \"fine_tuning.job.event\",\n",
            "      \"id\": \"ftevent-TV2SZpY4yQF20yAb33Y0xDiy\",\n",
            "      \"created_at\": 1700321930,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Files validated, moving job to queued state\",\n",
            "      \"data\": {},\n",
            "      \"type\": \"message\"\n",
            "    },\n",
            "    {\n",
            "      \"object\": \"fine_tuning.job.event\",\n",
            "      \"id\": \"ftevent-PoBkYNO60XsDujAiNDRkUqEw\",\n",
            "      \"created_at\": 1700321894,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Validating training file: file-3KvLZc6kKFMdNrn8Juuh2LvU\",\n",
            "      \"data\": {},\n",
            "      \"type\": \"message\"\n",
            "    },\n",
            "    {\n",
            "      \"object\": \"fine_tuning.job.event\",\n",
            "      \"id\": \"ftevent-tKUfUYHR6AWoQv3pLlSD4vUl\",\n",
            "      \"created_at\": 1700321894,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Created fine-tuning job: ftjob-XuAnm3MliLFIyjxoJFN0wyxC\",\n",
            "      \"data\": {},\n",
            "      \"type\": \"message\"\n",
            "    }\n",
            "  ],\n",
            "  \"has_more\": false\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Costo reale fine-tuning: 1.51$"
      ],
      "metadata": {
        "id": "OKYkT7HyOicY"
      }
    }
  ]
}